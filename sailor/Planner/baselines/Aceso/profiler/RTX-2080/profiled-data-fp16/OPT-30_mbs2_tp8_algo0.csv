op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,23015.434,3309.232,0.016,56.000,113.914,84.035,167.965,530.000
enc-1st-layernorm,387.555,1162.326,56.000,112.000,0.000,56.031,0.000,448.000
enc-attention-qkv,2859.420,22659.624,112.000,77.000,36.750,21.000,1.000,126.000
enc-attention-score,322.646,661.731,77.000,175.000,0.000,112.000,112.000,224.000
enc-attention-softmax,4416.955,6823.897,175.000,175.000,0.000,336.000,224.000,784.000
enc-attention-dropout,605.506,549.865,175.000,175.000,0.000,168.000,0.000,448.000
enc-attention-context,340.956,634.372,175.000,63.000,0.000,7.000,0.000,112.000
enc-attention-dense,20616.615,988.644,63.000,112.014,12.250,56.000,0.000,168.000
enc-post-attention-dropout,864.100,498.176,112.014,56.000,0.000,84.000,28.000,260.000
enc-2nd-layernorm,388.467,1164.979,56.000,112.000,0.000,56.031,0.000,448.000
enc-MLP-GEMM-1,3804.493,23259.264,112.000,84.007,49.000,28.000,0.000,140.000
enc-MLP-gelu,117.904,235.420,84.007,84.000,0.000,28.000,0.000,148.000
enc-MLP-GEMM-2,23214.537,3526.151,84.000,112.014,49.000,56.000,0.000,196.000
enc-post-MLP-dropout,868.899,498.140,112.014,56.000,0.000,84.000,28.000,260.000
final-layernorm,626.630,837.618,56.000,56.000,0.000,112.031,0.000,224.000
gpt-post-process,9374.845,26679.057,56.000,0.000,85.914,98.238,51.762,0.000
