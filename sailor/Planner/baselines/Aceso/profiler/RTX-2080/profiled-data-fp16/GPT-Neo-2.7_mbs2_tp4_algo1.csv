op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,7650.667,2295.214,0.016,20.000,166.562,30.035,49.965,296.000
enc-1st-layernorm,111.574,385.523,20.000,40.000,0.000,20.031,0.000,160.000
enc-attention-qkv,20416.135,1137.638,25.000,80.000,9.375,60.000,60.000,180.000
enc-attention-score,320.297,651.014,50.000,168.000,0.000,128.000,128.000,276.000
enc-attention-softmax,420.105,529.379,168.000,168.000,0.000,128.000,0.000,384.000
enc-attention-dropout,687.259,626.302,168.000,168.000,0.000,192.000,0.000,512.000
enc-attention-context,332.797,634.176,168.000,40.000,0.000,5.000,15.000,128.000
enc-attention-dense,6850.457,236.899,40.000,55.005,3.125,20.000,0.000,80.000
enc-post-attention-dropout,314.593,181.246,55.005,35.000,0.000,30.000,10.000,116.000
enc-2nd-layernorm,106.531,383.925,35.000,55.000,0.000,20.031,0.000,160.000
enc-MLP-GEMM-1,949.788,7598.180,55.000,55.005,12.500,20.000,0.000,80.000
enc-MLP-gelu,87.386,175.661,55.005,55.000,0.000,20.000,0.000,116.000
enc-MLP-GEMM-2,7535.321,898.784,55.000,55.005,12.500,20.000,0.000,80.000
enc-post-MLP-dropout,317.568,181.079,55.005,35.000,0.000,30.000,10.000,116.000
final-layernorm,206.906,762.749,35.000,35.000,0.000,40.031,0.000,80.000
gpt-post-process,20594.621,21016.884,35.000,15.000,156.562,502.051,251.949,0.000
