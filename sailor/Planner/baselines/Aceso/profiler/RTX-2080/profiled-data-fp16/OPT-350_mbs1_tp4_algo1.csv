op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1479.322,612.509,0.008,4.000,28.547,6.018,13.982,46.000
enc-1st-layernorm,104.469,198.096,4.000,8.000,0.000,4.016,0.000,20.000
enc-attention-qkv,4239.053,228.685,5.000,16.000,1.500,12.000,12.000,22.000
enc-attention-score,119.901,199.813,10.000,40.000,0.000,32.000,32.000,66.000
enc-attention-softmax,159.359,137.985,40.000,40.000,0.000,32.000,0.000,96.000
enc-attention-dropout,178.498,163.800,40.000,40.000,0.000,48.000,0.000,128.000
enc-attention-context,144.881,170.338,40.000,8.000,0.000,1.000,1.000,34.000
enc-attention-dense,1630.884,132.453,8.000,11.002,0.500,4.000,0.000,2.000
enc-post-attention-dropout,127.780,104.684,11.002,7.000,0.000,6.000,0.000,36.000
enc-2nd-layernorm,103.933,142.968,7.000,11.000,0.000,4.016,0.000,40.000
enc-MLP-GEMM-1,128.794,1646.590,11.000,11.002,2.000,4.000,0.000,20.000
enc-MLP-gelu,80.758,141.126,11.002,11.000,0.000,4.000,0.000,36.000
enc-MLP-GEMM-2,1550.692,131.667,11.000,11.002,2.000,4.000,0.000,20.000
enc-post-MLP-dropout,122.857,101.191,11.002,7.000,0.000,6.000,0.000,36.000
final-layernorm,104.409,480.169,7.000,7.000,0.000,4.016,0.000,20.000
gpt-post-process,3234.595,3244.531,7.000,3.000,24.547,98.213,51.787,0.000
