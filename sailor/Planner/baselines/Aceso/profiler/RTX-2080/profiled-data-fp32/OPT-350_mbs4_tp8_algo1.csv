op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,12851.197,1590.902,0.062,32.000,32.547,40.070,87.930,76.000
enc-1st-layernorm,135.964,535.667,32.000,64.000,0.000,32.062,0.000,128.000
enc-attention-qkv,34773.982,1064.247,36.000,128.000,1.500,96.000,96.000,96.000
enc-attention-score,418.544,809.926,72.000,192.000,0.000,128.000,128.000,20.000
enc-attention-softmax,1751.751,3123.105,192.000,192.000,0.000,128.000,128.000,256.000
enc-attention-dropout,615.042,567.967,192.000,192.000,0.000,160.000,0.000,256.000
enc-attention-context,505.275,806.677,192.000,64.000,0.000,4.000,0.000,128.000
enc-attention-dense,11468.679,169.837,64.000,92.004,0.500,32.000,0.000,32.000
enc-post-attention-dropout,467.145,272.059,92.004,60.000,0.000,40.000,24.000,98.000
enc-2nd-layernorm,136.197,537.992,60.000,92.000,0.000,32.062,0.000,128.000
enc-MLP-GEMM-1,618.416,12047.732,92.000,76.002,2.000,16.000,0.000,48.000
enc-MLP-gelu,68.921,139.767,76.002,76.000,0.000,16.000,0.000,64.000
enc-MLP-GEMM-2,11915.761,585.735,76.000,92.004,2.000,32.000,0.000,48.000
enc-post-MLP-dropout,474.286,273.550,92.004,60.000,0.000,40.000,24.000,98.000
final-layernorm,263.697,760.913,60.000,60.000,0.000,64.062,0.000,64.000
gpt-post-process,10862.637,19204.557,60.000,28.000,24.547,196.477,1.523,0.000
