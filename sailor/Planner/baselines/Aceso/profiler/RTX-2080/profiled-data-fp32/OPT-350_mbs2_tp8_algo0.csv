op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,6508.392,1037.127,0.031,16.000,32.547,20.035,43.965,96.000
enc-1st-layernorm,74.673,273.591,16.000,32.000,0.000,16.031,0.000,64.000
enc-attention-qkv,292.653,6178.689,32.000,22.000,1.500,6.375,0.000,16.000
enc-attention-score,214.720,607.288,22.000,82.000,0.000,64.000,64.000,0.000
enc-attention-softmax,879.192,1570.094,82.000,82.000,0.000,64.000,64.000,128.000
enc-attention-dropout,308.645,287.002,82.000,82.000,0.000,80.000,0.000,128.000
enc-attention-context,307.423,520.134,82.000,18.000,0.000,2.000,0.000,64.000
enc-attention-dense,5862.856,182.897,18.000,32.004,0.500,16.000,0.000,16.000
enc-post-attention-dropout,237.536,140.810,32.004,16.000,0.000,20.000,12.000,64.000
enc-2nd-layernorm,74.792,273.412,16.000,32.000,0.000,16.031,0.000,64.000
enc-MLP-GEMM-1,321.341,6167.120,32.000,24.002,2.000,8.000,0.000,16.000
enc-MLP-gelu,55.665,168.830,24.002,24.000,0.000,8.000,0.000,36.000
enc-MLP-GEMM-2,6080.061,298.941,24.000,32.004,2.000,16.000,0.000,16.000
enc-post-MLP-dropout,237.244,139.713,32.004,16.000,0.000,20.000,12.000,64.000
final-layernorm,134.617,837.088,16.000,16.000,0.000,32.031,0.000,32.000
gpt-post-process,5803.299,9829.694,16.000,0.000,24.547,98.238,1.762,0.000
