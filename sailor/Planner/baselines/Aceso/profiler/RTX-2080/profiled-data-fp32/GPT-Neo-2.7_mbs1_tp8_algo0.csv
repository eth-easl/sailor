op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,7954.341,2361.774,0.016,20.000,176.562,25.018,74.982,218.000
enc-1st-layernorm,115.043,392.294,20.000,40.000,0.000,20.016,0.000,80.000
enc-attention-qkv,823.122,8009.070,40.000,27.500,9.375,7.500,0.000,20.000
enc-attention-score,253.648,654.972,27.500,86.500,0.000,64.000,64.000,0.000
enc-attention-softmax,881.761,1570.368,86.500,86.500,0.000,64.000,64.000,128.000
enc-attention-dropout,312.614,287.139,86.500,86.500,0.000,80.000,0.000,128.000
enc-attention-context,341.684,603.998,86.500,22.500,0.000,2.500,0.000,64.000
enc-attention-dense,7380.176,287.586,22.500,40.010,3.125,20.000,0.000,20.000
enc-post-attention-dropout,295.871,172.740,40.010,20.000,0.000,25.000,15.000,76.000
enc-2nd-layernorm,115.222,392.032,20.000,40.000,0.000,20.016,0.000,80.000
enc-MLP-GEMM-1,1112.735,8146.346,40.000,30.005,12.500,10.000,0.000,30.000
enc-MLP-gelu,54.210,129.336,30.005,30.000,0.000,10.000,0.000,40.000
enc-MLP-GEMM-2,8058.536,945.425,30.000,40.010,12.500,20.000,0.000,30.000
enc-post-MLP-dropout,293.666,171.345,40.010,20.000,0.000,25.000,15.000,76.000
final-layernorm,115.103,480.407,20.000,20.000,0.000,20.016,0.000,40.000
gpt-post-process,14038.116,19056.004,20.000,0.000,156.562,126.025,0.000,0.000
