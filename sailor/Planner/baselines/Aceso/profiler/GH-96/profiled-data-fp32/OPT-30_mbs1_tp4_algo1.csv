op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,648.081,1129.895,0.016,56.000,406.000,70.018,167.982,462.000
enc-1st-layernorm,56.189,203.514,56.000,112.000,0.000,56.016,0.000,224.000
enc-attention-qkv,1630.616,529.212,70.000,224.000,147.000,168.000,0.000,168.000
enc-attention-score,97.811,226.945,140.000,336.000,0.000,224.000,224.000,42.000
enc-attention-softmax,663.519,909.805,336.000,336.000,0.000,224.000,224.000,448.000
enc-attention-dropout,183.523,172.657,336.000,336.000,0.000,280.000,0.000,448.000
enc-attention-context,107.783,185.931,336.000,112.000,0.000,14.000,0.000,238.000
enc-attention-dense,585.562,149.000,112.000,154.027,49.000,56.000,0.000,0.000
enc-post-attention-dropout,151.855,91.648,154.027,98.000,0.000,70.000,42.000,224.000
enc-2nd-layernorm,56.487,204.045,98.000,154.000,0.000,56.016,0.000,224.000
enc-MLP-GEMM-1,648.206,1229.376,154.000,154.027,196.000,56.000,0.000,112.000
enc-MLP-gelu,39.905,109.583,154.027,154.000,0.000,56.000,0.000,224.000
enc-MLP-GEMM-2,1092.446,660.193,154.000,154.027,196.000,56.000,0.000,112.000
enc-post-MLP-dropout,153.786,87.196,154.027,98.000,0.000,70.000,42.000,224.000
final-layernorm,56.791,231.642,98.000,98.000,0.000,56.016,0.000,112.000
gpt-post-process,1591.337,1622.194,98.000,42.000,350.000,100.025,0.000,0.000
