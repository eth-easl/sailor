op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,139.779,587.869,0.031,16.000,208.000,20.000,44.000,220.000
enc-1st-layernorm,37.169,97.352,16.000,32.000,0.000,16.031,0.000,64.000
enc-attention-qkv,182.223,131.702,32.000,64.000,12.000,48.000,48.000,64.000
enc-attention-score,182.313,365.490,64.000,544.000,0.000,512.000,512.000,48.000
enc-attention-softmax,1503.724,2064.818,544.000,544.000,0.000,512.000,512.000,1024.000
enc-attention-dropout,408.322,333.881,544.000,544.000,0.000,640.000,0.000,1024.000
enc-attention-context,191.766,346.863,544.000,32.000,0.000,16.000,16.000,528.000
enc-attention-dense,76.151,96.709,32.000,32.004,4.000,16.000,0.000,32.000
enc-post-attention-dropout,74.375,66.090,32.004,16.000,0.000,20.000,16.000,64.000
enc-2nd-layernorm,40.859,94.682,16.000,32.000,0.000,16.031,0.000,64.000
enc-MLP-GEMM-1,107.175,106.961,32.000,80.016,16.000,64.000,0.000,80.000
enc-MLP-gelu,44.411,103.980,80.016,80.000,0.000,64.000,0.000,256.000
enc-MLP-GEMM-2,104.260,113.553,80.000,32.004,16.000,16.000,0.000,80.000
enc-post-MLP-dropout,78.237,67.043,32.004,16.000,0.000,20.000,16.000,64.000
final-layernorm,59.760,337.613,16.000,16.000,0.000,32.031,0.000,32.000
gpt-post-process,3586.441,1799.834,16.000,0.000,200.000,800.051,0.000,0.000
