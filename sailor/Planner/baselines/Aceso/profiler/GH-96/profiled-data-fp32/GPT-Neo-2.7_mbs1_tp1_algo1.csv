op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,149.882,1858.425,0.016,20.000,1272.500,25.000,75.000,1254.000
enc-1st-layernorm,46.736,97.239,20.000,40.000,0.000,20.016,0.000,80.000
enc-attention-qkv,341.880,274.038,40.000,80.000,75.000,60.000,0.000,0.000
enc-attention-score,206.816,401.783,80.000,552.000,0.000,512.000,512.000,60.000
enc-attention-softmax,1482.058,2045.047,552.000,552.000,0.000,512.000,512.000,1024.000
enc-attention-dropout,409.573,334.692,552.000,552.000,0.000,640.000,0.000,1024.000
enc-attention-context,209.808,379.372,552.000,40.000,0.000,20.000,20.000,532.000
enc-attention-dense,97.376,111.884,40.000,40.010,25.000,20.000,0.000,0.000
enc-post-attention-dropout,88.602,70.047,40.010,20.000,0.000,25.000,35.000,80.000
enc-2nd-layernorm,45.222,95.850,20.000,40.000,0.000,20.016,0.000,80.000
enc-MLP-GEMM-1,330.484,337.172,40.000,100.039,100.000,80.000,0.000,0.000
enc-MLP-gelu,55.671,113.869,100.039,100.000,0.000,80.000,0.000,296.000
enc-MLP-GEMM-2,383.037,417.668,100.000,40.010,100.000,20.000,0.000,0.000
enc-post-MLP-dropout,84.990,72.694,40.010,20.000,0.000,25.000,35.000,80.000
final-layernorm,44.441,291.854,20.000,20.000,0.000,20.016,0.000,40.000
gpt-post-process,6347.090,4222.476,20.000,0.000,1252.500,1002.025,0.000,0.000
