op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,409.985,525.892,0.031,16.000,108.000,20.035,43.965,150.000
enc-1st-layernorm,42.075,99.826,16.000,32.000,0.000,16.031,0.000,64.000
enc-attention-qkv,826.299,164.580,24.000,64.000,6.000,48.000,48.000,68.000
enc-attention-score,101.066,196.731,48.000,288.000,0.000,256.000,256.000,40.000
enc-attention-softmax,766.212,1047.307,288.000,288.000,0.000,256.000,256.000,512.000
enc-attention-dropout,208.294,170.135,288.000,288.000,0.000,320.000,0.000,512.000
enc-attention-context,107.145,185.215,288.000,32.000,0.000,8.000,12.000,256.000
enc-attention-dense,376.976,116.646,32.000,40.004,2.000,16.000,0.000,36.000
enc-post-attention-dropout,83.953,71.728,40.004,24.000,0.000,20.000,16.000,64.000
enc-2nd-layernorm,42.528,97.901,24.000,40.000,0.000,16.031,0.000,64.000
enc-MLP-GEMM-1,105.643,403.267,40.000,56.008,8.000,32.000,0.000,48.000
enc-MLP-gelu,35.566,101.399,56.008,56.000,0.000,32.000,0.000,128.000
enc-MLP-GEMM-2,380.510,119.543,56.000,40.004,8.000,16.000,0.000,48.000
enc-post-MLP-dropout,86.266,73.051,40.004,24.000,0.000,20.000,16.000,64.000
final-layernorm,71.174,394.368,24.000,24.000,0.000,32.031,0.000,32.000
gpt-post-process,2001.464,1240.414,24.000,8.000,100.000,400.051,0.000,0.000
