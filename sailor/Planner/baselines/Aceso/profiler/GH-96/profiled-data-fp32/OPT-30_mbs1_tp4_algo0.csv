op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,648.081,1129.895,0.016,56.000,406.000,70.018,167.982,462.000
enc-1st-layernorm,56.189,203.514,56.000,112.000,0.000,56.016,0.000,224.000
enc-attention-qkv,515.175,1091.278,112.000,98.000,147.000,42.000,32.000,98.000
enc-attention-score,97.811,226.945,98.000,294.000,0.000,224.000,224.000,42.000
enc-attention-softmax,663.519,909.805,294.000,294.000,0.000,224.000,224.000,448.000
enc-attention-dropout,183.523,172.657,294.000,294.000,0.000,280.000,0.000,448.000
enc-attention-context,107.783,185.931,294.000,70.000,0.000,14.000,0.000,238.000
enc-attention-dense,576.293,150.222,70.000,112.027,49.000,56.000,0.000,0.000
enc-post-attention-dropout,151.855,91.648,112.027,56.000,0.000,70.000,42.000,224.000
enc-2nd-layernorm,56.487,204.045,56.000,112.000,0.000,56.016,0.000,224.000
enc-MLP-GEMM-1,681.221,1200.229,112.000,112.027,196.000,56.000,0.000,112.000
enc-MLP-gelu,39.905,109.583,112.027,112.000,0.000,56.000,0.000,224.000
enc-MLP-GEMM-2,1074.153,636.691,112.000,112.027,196.000,56.000,0.000,112.000
enc-post-MLP-dropout,153.786,87.196,112.027,56.000,0.000,70.000,42.000,224.000
final-layernorm,56.791,231.642,56.000,56.000,0.000,56.016,0.000,112.000
gpt-post-process,1591.337,1622.194,56.000,0.000,350.000,100.025,0.000,0.000
