op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,926.125,1523.370,0.016,56.000,756.000,70.018,167.982,812.000
enc-1st-layernorm,56.326,202.751,56.000,112.000,0.000,56.016,0.000,224.000
enc-attention-qkv,1075.178,1974.320,112.000,140.000,294.000,84.000,88.000,140.000
enc-attention-score,175.935,401.449,140.000,532.000,0.000,448.000,448.000,84.000
enc-attention-softmax,1318.347,1793.641,532.000,532.000,0.000,448.000,448.000,896.000
enc-attention-dropout,359.517,293.118,532.000,532.000,0.000,560.000,0.000,896.000
enc-attention-context,204.873,352.448,532.000,84.000,0.000,28.000,28.000,476.000
enc-attention-dense,1016.319,295.156,84.000,112.027,98.000,56.000,0.000,0.000
enc-post-attention-dropout,151.551,81.074,112.027,56.000,0.000,70.000,42.000,224.000
enc-2nd-layernorm,56.440,203.246,56.000,112.000,0.000,56.016,0.000,224.000
enc-MLP-GEMM-1,1408.058,2105.939,112.000,168.055,392.000,112.000,0.000,168.000
enc-MLP-gelu,80.097,146.979,168.055,168.000,0.000,112.000,0.000,358.000
enc-MLP-GEMM-2,1976.359,1077.002,168.000,112.027,392.000,56.000,0.000,168.000
enc-post-MLP-dropout,154.775,79.298,112.027,56.000,0.000,70.000,42.000,224.000
final-layernorm,56.916,219.613,56.000,56.000,0.000,56.016,0.000,112.000
gpt-post-process,2747.083,2901.596,56.000,0.000,700.000,200.025,0.000,0.000
