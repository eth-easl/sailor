op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1839.441,2042.919,0.125,160.000,333.125,200.141,439.859,810.000
enc-1st-layernorm,116.098,404.269,160.000,320.000,0.000,160.125,0.000,640.000
enc-attention-qkv,561.702,1790.428,320.000,280.000,18.750,120.000,32.000,280.000
enc-attention-score,405.413,762.773,280.000,1224.000,0.000,1024.000,1024.000,120.000
enc-attention-softmax,2994.853,4101.276,1224.000,1224.000,0.000,1024.000,1024.000,2048.000
enc-attention-dropout,813.073,661.469,1224.000,1224.000,0.000,1280.000,0.000,2048.000
enc-attention-context,393.575,779.504,1224.000,200.000,0.000,40.000,40.000,1064.000
enc-attention-dense,1061.863,208.038,200.000,320.010,6.250,160.000,0.000,200.000
enc-post-attention-dropout,405.276,245.100,320.010,160.000,0.000,200.000,160.000,454.000
enc-2nd-layernorm,116.819,404.370,160.000,320.000,0.000,160.125,0.000,640.000
enc-MLP-GEMM-1,644.982,1808.941,320.000,320.010,25.000,160.000,0.000,320.000
enc-MLP-gelu,112.647,211.257,320.010,320.000,0.000,160.000,0.000,454.000
enc-MLP-GEMM-2,1520.175,658.500,320.000,320.010,25.000,160.000,0.000,320.000
enc-post-MLP-dropout,407.201,250.721,320.010,160.000,0.000,200.000,160.000,454.000
final-layernorm,251.627,337.183,160.000,160.000,0.000,320.125,0.000,320.000
gpt-post-process,12907.416,9697.747,160.000,0.000,313.125,2004.203,0.000,0.000
