op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,314.486,767.821,0.062,32.000,104.000,48.000,96.000,236.000
enc-1st-layernorm,53.954,138.903,32.000,64.000,0.000,32.125,0.000,256.000
enc-attention-qkv,295.979,273.472,64.000,128.000,6.000,96.000,96.000,320.000
enc-attention-score,367.242,685.281,128.000,1088.000,0.000,1024.000,1024.000,2144.000
enc-attention-softmax,668.359,1101.309,1088.000,1088.000,0.000,1024.000,0.000,3072.000
enc-attention-dropout,1141.977,751.078,1088.000,1088.000,0.000,1536.000,0.000,4096.000
enc-attention-context,377.166,681.406,1088.000,64.000,0.000,32.000,32.000,1120.000
enc-attention-dense,83.333,88.102,64.000,64.002,2.000,32.000,0.000,128.000
enc-post-attention-dropout,120.854,69.010,64.002,32.000,0.000,48.000,32.000,256.000
enc-2nd-layernorm,53.972,139.630,32.000,64.000,0.000,32.125,0.000,256.000
enc-MLP-GEMM-1,216.228,175.571,64.000,160.008,8.000,128.000,0.000,416.000
enc-MLP-gelu,127.298,211.221,160.008,160.000,0.000,128.000,0.000,644.000
enc-MLP-GEMM-2,205.600,210.065,160.000,64.002,8.000,32.000,0.000,160.000
enc-post-MLP-dropout,125.933,71.168,64.002,32.000,0.000,48.000,32.000,256.000
final-layernorm,107.861,396.591,32.000,32.000,0.000,64.125,0.000,128.000
gpt-post-process,13738.477,6986.696,32.000,0.000,100.000,3200.203,1599.797,0.000
