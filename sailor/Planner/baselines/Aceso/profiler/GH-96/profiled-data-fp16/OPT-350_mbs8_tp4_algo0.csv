op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,557.560,795.883,0.062,32.000,29.000,48.141,95.859,186.000
enc-1st-layernorm,53.012,138.867,32.000,64.000,0.000,32.125,0.000,256.000
enc-attention-qkv,177.079,434.428,64.000,56.000,1.500,24.000,8.000,108.000
enc-attention-score,193.578,190.794,56.000,296.000,0.000,256.000,256.000,552.000
enc-attention-softmax,173.962,281.572,296.000,296.000,0.000,256.000,0.000,768.000
enc-attention-dropout,292.313,191.647,296.000,296.000,0.000,384.000,0.000,1024.000
enc-attention-context,135.970,247.926,296.000,40.000,0.000,8.000,12.000,272.000
enc-attention-dense,372.058,104.165,40.000,64.002,0.500,32.000,0.000,96.000
enc-post-attention-dropout,119.084,72.020,64.002,32.000,0.000,48.000,32.000,256.000
enc-2nd-layernorm,52.673,139.326,32.000,64.000,0.000,32.125,0.000,256.000
enc-MLP-GEMM-1,103.480,391.227,64.000,64.002,2.000,32.000,0.000,128.000
enc-MLP-gelu,44.322,102.377,64.002,64.000,0.000,32.000,0.000,256.000
enc-MLP-GEMM-2,375.366,113.147,64.000,64.002,2.000,32.000,0.000,128.000
enc-post-MLP-dropout,119.776,73.618,64.002,32.000,0.000,48.000,32.000,256.000
final-layernorm,97.251,337.929,32.000,32.000,0.000,64.125,0.000,128.000
gpt-post-process,3802.872,2181.977,32.000,0.000,25.000,800.203,399.797,0.000
