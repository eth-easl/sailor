op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,931.591,1182.985,0.016,56.000,203.000,84.035,167.965,620.000
enc-1st-layernorm,92.977,231.427,56.000,112.000,0.000,56.031,0.000,448.000
enc-attention-qkv,1798.832,632.071,70.000,224.000,73.500,168.000,168.000,504.000
enc-attention-score,132.883,195.271,140.000,336.000,0.000,224.000,224.000,490.000
enc-attention-softmax,153.863,246.567,336.000,336.000,0.000,224.000,0.000,672.000
enc-attention-dropout,256.658,168.353,336.000,336.000,0.000,336.000,0.000,896.000
enc-attention-context,125.515,175.363,336.000,112.000,0.000,14.000,0.000,266.000
enc-attention-dense,569.504,139.952,112.000,154.014,24.500,56.000,0.000,168.000
enc-post-attention-dropout,199.556,85.497,154.014,98.000,0.000,84.000,56.000,358.000
enc-2nd-layernorm,82.362,225.693,98.000,154.000,0.000,56.031,0.000,448.000
enc-MLP-GEMM-1,657.952,1199.341,154.000,154.014,98.000,56.000,0.000,224.000
enc-MLP-gelu,59.211,105.572,154.014,154.000,0.000,56.000,0.000,358.000
enc-MLP-GEMM-2,1090.348,586.331,154.000,154.014,98.000,56.000,0.000,224.000
enc-post-MLP-dropout,213.629,85.753,154.014,98.000,0.000,84.000,56.000,358.000
final-layernorm,183.231,349.969,98.000,98.000,0.000,112.031,0.000,224.000
gpt-post-process,2082.920,1893.264,98.000,42.000,175.000,200.051,99.949,0.000
