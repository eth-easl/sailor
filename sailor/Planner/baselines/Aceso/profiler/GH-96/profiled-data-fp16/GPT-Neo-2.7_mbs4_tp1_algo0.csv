op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,386.691,1532.054,0.031,40.000,636.250,60.000,120.000,796.000
enc-1st-layernorm,55.325,143.665,40.000,80.000,0.000,40.062,0.000,320.000
enc-attention-qkv,643.486,686.240,80.000,160.000,37.500,120.000,152.000,400.000
enc-attention-score,429.916,723.708,160.000,1104.000,0.000,1024.000,1024.000,2168.000
enc-attention-softmax,666.535,1098.752,1104.000,1104.000,0.000,1024.000,0.000,3072.000
enc-attention-dropout,1139.545,750.405,1104.000,1104.000,0.000,1536.000,0.000,4096.000
enc-attention-context,394.678,711.763,1104.000,80.000,0.000,40.000,40.000,1144.000
enc-attention-dense,185.913,149.560,80.000,80.005,12.500,40.000,0.000,160.000
enc-post-attention-dropout,151.241,66.626,80.005,40.000,0.000,60.000,40.000,294.000
enc-2nd-layernorm,56.863,145.614,40.000,80.000,0.000,40.062,0.000,320.000
enc-MLP-GEMM-1,645.304,693.005,80.000,200.020,50.000,160.000,0.000,520.000
enc-MLP-gelu,202.751,263.244,200.020,200.000,0.000,160.000,0.000,776.000
enc-MLP-GEMM-2,616.419,751.758,200.000,80.005,50.000,40.000,0.000,240.000
enc-post-MLP-dropout,176.144,70.882,80.005,40.000,0.000,60.000,40.000,294.000
final-layernorm,143.921,382.662,40.000,40.000,0.000,80.062,0.000,160.000
gpt-post-process,20441.240,12237.936,40.000,0.000,626.250,4008.102,2003.898,0.000
