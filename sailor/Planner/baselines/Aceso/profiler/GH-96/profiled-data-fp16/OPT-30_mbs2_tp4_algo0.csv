op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,931.591,1182.985,0.016,56.000,203.000,84.035,167.965,620.000
enc-1st-layernorm,92.977,231.427,56.000,112.000,0.000,56.031,0.000,448.000
enc-attention-qkv,548.619,1097.095,112.000,98.000,73.500,42.000,0.000,168.000
enc-attention-score,132.883,195.271,98.000,294.000,0.000,224.000,224.000,490.000
enc-attention-softmax,153.863,246.567,294.000,294.000,0.000,224.000,0.000,672.000
enc-attention-dropout,256.658,168.353,294.000,294.000,0.000,336.000,0.000,896.000
enc-attention-context,125.515,175.363,294.000,70.000,0.000,14.000,0.000,266.000
enc-attention-dense,562.423,139.314,70.000,112.014,24.500,56.000,0.000,168.000
enc-post-attention-dropout,199.556,85.497,112.014,56.000,0.000,84.000,56.000,358.000
enc-2nd-layernorm,82.362,225.693,56.000,112.000,0.000,56.031,0.000,448.000
enc-MLP-GEMM-1,616.980,1269.192,112.000,112.014,98.000,56.000,0.000,224.000
enc-MLP-gelu,59.211,105.572,112.014,112.000,0.000,56.000,0.000,358.000
enc-MLP-GEMM-2,1058.370,599.426,112.000,112.014,98.000,56.000,0.000,224.000
enc-post-MLP-dropout,213.629,85.753,112.014,56.000,0.000,84.000,56.000,358.000
final-layernorm,183.231,349.969,56.000,56.000,0.000,112.031,0.000,224.000
gpt-post-process,2082.920,1893.264,56.000,0.000,175.000,200.051,99.949,0.000
