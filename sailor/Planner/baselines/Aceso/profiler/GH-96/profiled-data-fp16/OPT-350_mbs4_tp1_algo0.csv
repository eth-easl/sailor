op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,174.218,585.538,0.031,16.000,104.000,24.000,40.000,168.000
enc-1st-layernorm,51.618,95.391,16.000,32.000,0.000,16.062,0.000,128.000
enc-attention-qkv,163.651,137.377,32.000,64.000,6.000,48.000,48.000,160.000
enc-attention-score,193.202,361.603,64.000,544.000,0.000,512.000,512.000,1072.000
enc-attention-softmax,338.733,552.803,544.000,544.000,0.000,512.000,0.000,1536.000
enc-attention-dropout,575.572,378.180,544.000,544.000,0.000,768.000,0.000,2048.000
enc-attention-context,195.158,349.200,544.000,32.000,0.000,16.000,16.000,560.000
enc-attention-dense,73.498,89.806,32.000,32.002,2.000,16.000,0.000,64.000
enc-post-attention-dropout,98.538,69.982,32.002,16.000,0.000,24.000,28.000,128.000
enc-2nd-layernorm,51.099,97.901,16.000,32.000,0.000,16.062,0.000,128.000
enc-MLP-GEMM-1,110.149,90.015,32.000,80.008,8.000,64.000,0.000,208.000
enc-MLP-gelu,65.202,106.764,80.008,80.000,0.000,64.000,0.000,388.000
enc-MLP-GEMM-2,102.824,99.045,80.000,32.002,8.000,16.000,0.000,80.000
enc-post-MLP-dropout,97.185,70.196,32.002,16.000,0.000,24.000,28.000,128.000
final-layernorm,74.345,404.060,16.000,16.000,0.000,32.062,0.000,64.000
gpt-post-process,7019.246,3609.473,16.000,0.000,100.000,1600.102,799.898,0.000
