op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,503.427,724.179,0.016,20.000,166.562,30.035,59.965,286.000
enc-1st-layernorm,45.246,95.391,20.000,40.000,0.000,20.031,0.000,160.000
enc-attention-qkv,159.609,454.539,40.000,35.000,9.375,15.625,32.375,40.000
enc-attention-score,78.815,144.136,35.000,153.000,0.000,128.000,128.000,276.000
enc-attention-softmax,91.743,145.966,153.000,153.000,0.000,128.000,0.000,384.000
enc-attention-dropout,149.626,98.157,153.000,153.000,0.000,192.000,0.000,512.000
enc-attention-context,90.885,122.184,153.000,25.000,0.000,5.000,0.000,138.000
enc-attention-dense,363.600,94.002,25.000,40.005,3.125,20.000,0.000,80.000
enc-post-attention-dropout,87.476,65.619,40.005,20.000,0.000,30.000,20.000,160.000
enc-2nd-layernorm,42.546,92.679,20.000,40.000,0.000,20.031,0.000,160.000
enc-MLP-GEMM-1,84.984,392.056,40.000,40.005,12.500,20.000,0.000,80.000
enc-MLP-gelu,40.185,97.615,40.005,40.000,0.000,20.000,0.000,160.000
enc-MLP-GEMM-2,347.430,97.406,40.000,40.005,12.500,20.000,0.000,80.000
enc-post-MLP-dropout,90.116,67.991,40.005,20.000,0.000,30.000,20.000,160.000
final-layernorm,67.931,324.744,20.000,20.000,0.000,40.031,0.000,80.000
gpt-post-process,3045.291,2104.443,20.000,0.000,156.562,502.051,251.949,0.000
