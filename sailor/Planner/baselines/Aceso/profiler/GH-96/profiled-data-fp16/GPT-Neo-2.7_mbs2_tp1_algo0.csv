op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,196.254,1370.931,0.016,20.000,636.250,30.000,0.000,628.000
enc-1st-layernorm,50.122,99.003,20.000,40.000,0.000,20.031,0.000,160.000
enc-attention-qkv,323.826,285.065,40.000,80.000,37.500,60.000,72.000,200.000
enc-attention-score,216.746,382.572,80.000,552.000,0.000,512.000,512.000,1084.000
enc-attention-softmax,339.341,552.917,552.000,552.000,0.000,512.000,0.000,1536.000
enc-attention-dropout,574.178,378.489,552.000,552.000,0.000,768.000,0.000,2048.000
enc-attention-context,206.423,362.682,552.000,40.000,0.000,20.000,20.000,572.000
enc-attention-dense,81.837,88.429,40.000,40.005,12.500,20.000,0.000,80.000
enc-post-attention-dropout,97.644,66.066,40.005,20.000,0.000,30.000,20.000,160.000
enc-2nd-layernorm,46.170,93.895,20.000,40.000,0.000,20.031,0.000,160.000
enc-MLP-GEMM-1,326.270,313.753,40.000,100.020,50.000,80.000,0.000,260.000
enc-MLP-gelu,83.125,127.202,100.020,100.000,0.000,80.000,0.000,456.000
enc-MLP-GEMM-2,307.113,275.558,100.000,40.005,50.000,20.000,0.000,140.000
enc-post-MLP-dropout,100.785,68.736,40.005,20.000,0.000,30.000,20.000,160.000
final-layernorm,77.230,385.553,20.000,20.000,0.000,40.031,0.000,80.000
gpt-post-process,10548.377,6267.834,20.000,0.000,626.250,2004.051,1001.949,0.000
