op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,719.649,852.549,0.062,32.000,54.000,48.141,95.859,250.000
enc-1st-layernorm,53.859,139.064,32.000,64.000,0.000,32.125,0.000,256.000
enc-attention-qkv,190.473,608.015,64.000,80.000,3.000,48.000,32.000,176.000
enc-attention-score,237.119,361.472,80.000,560.000,0.000,512.000,512.000,1072.000
enc-attention-softmax,338.799,555.730,560.000,560.000,0.000,512.000,0.000,1536.000
enc-attention-dropout,578.344,378.251,560.000,560.000,0.000,768.000,0.000,2048.000
enc-attention-context,195.408,349.903,560.000,48.000,0.000,16.000,16.000,560.000
enc-attention-dense,553.674,111.085,48.000,64.002,1.000,32.000,0.000,112.000
enc-post-attention-dropout,119.597,81.366,64.002,32.000,0.000,48.000,32.000,256.000
enc-2nd-layernorm,53.489,138.915,32.000,64.000,0.000,32.125,0.000,256.000
enc-MLP-GEMM-1,112.736,568.593,64.000,96.004,4.000,64.000,0.000,224.000
enc-MLP-gelu,65.660,112.468,96.004,96.000,0.000,64.000,0.000,388.000
enc-MLP-GEMM-2,567.001,118.202,96.000,64.002,4.000,32.000,0.000,160.000
enc-post-MLP-dropout,119.436,90.384,64.002,32.000,0.000,48.000,32.000,256.000
final-layernorm,97.984,353.950,32.000,32.000,0.000,64.125,0.000,128.000
gpt-post-process,7131.302,4052.317,32.000,0.000,50.000,1600.203,799.797,0.000
