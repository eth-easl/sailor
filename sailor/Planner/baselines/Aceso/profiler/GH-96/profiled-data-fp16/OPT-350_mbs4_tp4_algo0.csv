op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,408.340,537.509,0.031,16.000,29.000,24.070,39.930,130.000
enc-1st-layernorm,47.141,103.581,16.000,32.000,0.000,16.062,0.000,128.000
enc-attention-qkv,180.697,350.851,32.000,28.000,1.500,12.000,20.000,36.000
enc-attention-score,113.928,154.257,28.000,148.000,0.000,128.000,128.000,256.000
enc-attention-softmax,92.161,143.313,148.000,148.000,0.000,128.000,0.000,384.000
enc-attention-dropout,149.757,98.264,148.000,148.000,0.000,192.000,0.000,512.000
enc-attention-context,105.870,148.982,148.000,20.000,0.000,4.000,0.000,148.000
enc-attention-dense,286.120,106.090,20.000,32.002,0.500,16.000,0.000,68.000
enc-post-attention-dropout,94.169,75.471,32.002,16.000,0.000,24.000,28.000,128.000
enc-2nd-layernorm,47.004,104.934,16.000,32.000,0.000,16.062,0.000,128.000
enc-MLP-GEMM-1,99.957,306.433,32.000,32.002,2.000,16.000,0.000,64.000
enc-MLP-gelu,42.015,102.115,32.002,32.000,0.000,16.000,0.000,128.000
enc-MLP-GEMM-2,286.841,103.277,32.000,32.002,2.000,16.000,0.000,64.000
enc-post-MLP-dropout,92.608,73.749,32.002,16.000,0.000,24.000,28.000,128.000
final-layernorm,72.551,343.335,16.000,16.000,0.000,32.062,0.000,64.000
gpt-post-process,2053.612,1217.282,16.000,0.000,25.000,400.102,199.898,0.000
