op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,557.560,795.883,0.062,32.000,29.000,48.141,95.859,186.000
enc-1st-layernorm,53.012,138.867,32.000,64.000,0.000,32.125,0.000,256.000
enc-attention-qkv,879.121,175.315,40.000,128.000,1.500,96.000,96.000,288.000
enc-attention-score,193.578,190.794,80.000,320.000,0.000,256.000,256.000,552.000
enc-attention-softmax,173.962,281.572,320.000,320.000,0.000,256.000,0.000,768.000
enc-attention-dropout,292.313,191.647,320.000,320.000,0.000,384.000,0.000,1024.000
enc-attention-context,135.970,247.926,320.000,64.000,0.000,8.000,12.000,272.000
enc-attention-dense,371.361,112.140,64.000,88.002,0.500,32.000,0.000,96.000
enc-post-attention-dropout,119.084,72.020,88.002,56.000,0.000,48.000,32.000,256.000
enc-2nd-layernorm,52.673,139.326,56.000,88.000,0.000,32.125,0.000,256.000
enc-MLP-GEMM-1,103.348,386.417,88.000,88.002,2.000,32.000,0.000,128.000
enc-MLP-gelu,44.322,102.377,88.002,88.000,0.000,32.000,0.000,256.000
enc-MLP-GEMM-2,373.179,114.465,88.000,88.002,2.000,32.000,0.000,128.000
enc-post-MLP-dropout,119.776,73.618,88.002,56.000,0.000,48.000,32.000,256.000
final-layernorm,97.251,337.929,56.000,56.000,0.000,64.125,0.000,128.000
gpt-post-process,3802.872,2181.977,56.000,24.000,25.000,800.203,399.797,0.000
