op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,408.340,537.509,0.031,16.000,29.000,24.070,39.930,130.000
enc-1st-layernorm,47.141,103.581,16.000,32.000,0.000,16.062,0.000,128.000
enc-attention-qkv,557.768,151.390,20.000,64.000,1.500,48.000,48.000,144.000
enc-attention-score,113.928,154.257,40.000,160.000,0.000,128.000,128.000,256.000
enc-attention-softmax,92.161,143.313,160.000,160.000,0.000,128.000,0.000,384.000
enc-attention-dropout,149.757,98.264,160.000,160.000,0.000,192.000,0.000,512.000
enc-attention-context,105.870,148.982,160.000,32.000,0.000,4.000,0.000,148.000
enc-attention-dense,284.338,103.706,32.000,44.002,0.500,16.000,0.000,68.000
enc-post-attention-dropout,94.169,75.471,44.002,28.000,0.000,24.000,28.000,128.000
enc-2nd-layernorm,47.004,104.934,28.000,44.000,0.000,16.062,0.000,128.000
enc-MLP-GEMM-1,97.358,305.212,44.000,44.002,2.000,16.000,0.000,64.000
enc-MLP-gelu,42.015,102.115,44.002,44.000,0.000,16.000,0.000,128.000
enc-MLP-GEMM-2,286.841,103.283,44.000,44.002,2.000,16.000,0.000,64.000
enc-post-MLP-dropout,92.608,73.749,44.002,28.000,0.000,24.000,28.000,128.000
final-layernorm,72.551,343.335,28.000,28.000,0.000,32.062,0.000,64.000
gpt-post-process,2053.612,1217.282,28.000,12.000,25.000,400.102,199.898,0.000
