op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,701.916,2786.571,0.031,40.000,636.250,60.000,120.000,796.000
enc-1st-layernorm,91.112,317.967,40.000,80.000,0.000,40.062,0.000,320.000
enc-attention-qkv,1971.221,1570.636,80.000,160.000,37.500,120.000,120.000,400.000
enc-attention-score,1152.498,1914.829,160.000,1104.000,0.000,1024.000,1024.000,2168.000
enc-attention-softmax,1380.509,1861.691,1104.000,1104.000,0.000,1024.000,0.000,3072.000
enc-attention-dropout,2343.297,1955.640,1104.000,1104.000,0.000,1536.000,0.000,4096.000
enc-attention-context,1084.250,2073.401,1104.000,80.000,0.000,40.000,40.000,1144.000
enc-attention-dense,436.604,399.196,80.000,80.005,12.500,40.000,0.000,160.000
enc-post-attention-dropout,289.899,150.669,80.005,40.000,0.000,60.000,40.000,270.000
enc-2nd-layernorm,91.034,328.714,40.000,80.000,0.000,40.062,0.000,320.000
enc-MLP-GEMM-1,1931.536,1515.555,80.000,200.020,50.000,160.000,0.000,520.000
enc-MLP-gelu,292.188,529.009,200.020,200.000,0.000,160.000,0.000,750.000
enc-MLP-GEMM-2,1640.803,1639.771,200.000,80.005,50.000,40.000,0.000,280.000
enc-post-MLP-dropout,290.877,148.696,80.005,40.000,0.000,60.000,40.000,270.000
final-layernorm,191.087,629.342,40.000,40.000,0.000,80.062,0.000,160.000
gpt-post-process,49519.414,30944.383,40.000,0.000,626.250,4008.102,2003.898,0.000
