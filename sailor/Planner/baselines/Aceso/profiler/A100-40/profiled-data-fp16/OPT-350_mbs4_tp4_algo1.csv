op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,606.471,744.033,0.031,16.000,28.547,24.070,23.930,126.000
enc-1st-layernorm,78.237,143.880,16.000,32.000,0.000,16.062,0.000,128.000
enc-attention-qkv,891.179,217.026,20.000,64.000,1.500,48.000,48.000,144.000
enc-attention-score,247.645,262.564,40.000,160.000,0.000,128.000,128.000,276.000
enc-attention-softmax,182.247,247.705,160.000,160.000,0.000,128.000,0.000,384.000
enc-attention-dropout,297.177,252.140,160.000,160.000,0.000,192.000,0.000,512.000
enc-attention-context,146.377,372.863,160.000,32.000,0.000,4.000,0.000,148.000
enc-attention-dense,476.974,127.250,32.000,44.002,0.500,16.000,0.000,48.000
enc-post-attention-dropout,117.034,100.738,44.002,28.000,0.000,24.000,8.000,128.000
enc-2nd-layernorm,79.006,141.531,28.000,44.000,0.000,16.062,0.000,128.000
enc-MLP-GEMM-1,116.211,490.206,44.000,44.002,2.000,16.000,0.000,64.000
enc-MLP-gelu,63.527,121.188,44.002,44.000,0.000,16.000,0.000,128.000
enc-MLP-GEMM-2,479.668,124.812,44.000,44.002,2.000,16.000,0.000,64.000
enc-post-MLP-dropout,116.527,98.634,44.002,28.000,0.000,24.000,8.000,128.000
final-layernorm,111.669,633.883,28.000,28.000,0.000,32.062,0.000,64.000
gpt-post-process,4216.588,2535.897,28.000,12.000,24.547,392.852,199.148,0.000
