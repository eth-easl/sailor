op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,352.430,2505.302,0.016,20.000,636.250,30.000,0.000,628.000
enc-1st-layernorm,76.991,174.350,20.000,40.000,0.000,20.031,0.000,160.000
enc-attention-qkv,995.505,718.534,40.000,80.000,37.500,60.000,0.000,0.000
enc-attention-score,578.934,977.683,80.000,552.000,0.000,512.000,512.000,1084.000
enc-attention-softmax,697.297,945.419,552.000,552.000,0.000,512.000,0.000,1536.000
enc-attention-dropout,1174.146,983.745,552.000,552.000,0.000,768.000,0.000,2048.000
enc-attention-context,555.581,1036.990,552.000,40.000,0.000,20.000,20.000,572.000
enc-attention-dense,227.839,205.278,40.000,40.005,12.500,20.000,0.000,0.000
enc-post-attention-dropout,148.898,96.416,40.005,20.000,0.000,30.000,10.000,160.000
enc-2nd-layernorm,78.243,176.179,20.000,40.000,0.000,20.031,0.000,160.000
enc-MLP-GEMM-1,958.622,759.482,40.000,100.020,50.000,80.000,0.000,0.000
enc-MLP-gelu,148.535,281.709,100.020,100.000,0.000,80.000,0.000,430.000
enc-MLP-GEMM-2,773.871,829.929,100.000,40.005,50.000,20.000,0.000,0.000
enc-post-MLP-dropout,149.810,99.009,40.005,20.000,0.000,30.000,10.000,160.000
final-layernorm,114.119,628.138,20.000,20.000,0.000,40.031,0.000,80.000
gpt-post-process,24902.838,15395.015,20.000,0.000,626.250,2004.051,1001.949,0.000
