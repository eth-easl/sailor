op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,924.885,1679.939,0.008,28.000,199.828,42.018,83.982,312.000
enc-1st-layernorm,103.092,281.799,28.000,56.000,0.000,28.016,0.000,224.000
enc-attention-qkv,1838.189,865.340,35.000,112.000,73.500,84.000,84.000,252.000
enc-attention-score,178.713,287.127,70.000,168.000,0.000,112.000,112.000,244.000
enc-attention-softmax,1895.058,2707.618,168.000,168.000,0.000,336.000,224.000,784.000
enc-attention-dropout,267.857,221.485,168.000,168.000,0.000,168.000,0.000,448.000
enc-attention-context,160.438,303.662,168.000,56.000,0.000,7.000,0.000,126.000
enc-attention-dense,655.991,224.280,56.000,77.014,24.500,28.000,0.000,84.000
enc-post-attention-dropout,202.739,109.828,77.014,49.000,0.000,42.000,14.000,222.000
enc-2nd-layernorm,100.362,282.091,49.000,77.000,0.000,28.016,0.000,224.000
enc-MLP-GEMM-1,820.637,1495.284,77.000,77.014,98.000,28.000,0.000,112.000
enc-MLP-gelu,62.615,133.359,77.014,77.000,0.000,28.000,0.000,222.000
enc-MLP-GEMM-2,1266.134,874.114,77.000,77.014,98.000,28.000,0.000,112.000
enc-post-MLP-dropout,203.174,108.975,77.014,49.000,0.000,42.000,14.000,222.000
final-layernorm,101.107,419.790,49.000,49.000,0.000,28.016,0.000,112.000
gpt-post-process,2585.131,2417.725,49.000,21.000,171.828,98.213,51.787,0.000
