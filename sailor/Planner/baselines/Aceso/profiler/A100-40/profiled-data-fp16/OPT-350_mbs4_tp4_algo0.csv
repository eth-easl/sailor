op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,606.471,744.033,0.031,16.000,28.547,24.070,23.930,126.000
enc-1st-layernorm,78.237,143.880,16.000,32.000,0.000,16.062,0.000,128.000
enc-attention-qkv,255.084,556.707,32.000,28.000,1.500,12.000,0.000,48.000
enc-attention-score,247.645,262.564,28.000,148.000,0.000,128.000,128.000,276.000
enc-attention-softmax,182.247,247.705,148.000,148.000,0.000,128.000,0.000,384.000
enc-attention-dropout,297.177,252.140,148.000,148.000,0.000,192.000,0.000,512.000
enc-attention-context,146.377,372.863,148.000,20.000,0.000,4.000,0.000,148.000
enc-attention-dense,523.019,124.955,20.000,32.002,0.500,16.000,0.000,48.000
enc-post-attention-dropout,117.034,100.738,32.002,16.000,0.000,24.000,8.000,128.000
enc-2nd-layernorm,79.006,141.531,16.000,32.000,0.000,16.062,0.000,128.000
enc-MLP-GEMM-1,116.628,512.516,32.000,32.002,2.000,16.000,0.000,64.000
enc-MLP-gelu,63.527,121.188,32.002,32.000,0.000,16.000,0.000,128.000
enc-MLP-GEMM-2,487.757,125.748,32.000,32.002,2.000,16.000,0.000,64.000
enc-post-MLP-dropout,116.527,98.634,32.002,16.000,0.000,24.000,8.000,128.000
final-layernorm,111.669,633.883,16.000,16.000,0.000,32.062,0.000,64.000
gpt-post-process,4216.588,2535.897,16.000,0.000,24.547,392.852,199.148,0.000
