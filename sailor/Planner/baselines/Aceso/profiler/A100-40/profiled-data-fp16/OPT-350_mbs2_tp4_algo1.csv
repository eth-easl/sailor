op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,592.238,699.151,0.016,8.000,28.547,12.035,7.965,66.000
enc-1st-layernorm,79.173,222.403,8.000,16.000,0.000,8.031,11.969,72.000
enc-attention-qkv,715.035,223.684,10.000,32.000,1.500,24.000,24.000,76.000
enc-attention-score,127.912,243.831,20.000,80.000,0.000,64.000,64.000,128.000
enc-attention-softmax,139.272,133.413,80.000,80.000,0.000,64.000,0.000,192.000
enc-attention-dropout,150.621,132.352,80.000,80.000,0.000,96.000,0.000,256.000
enc-attention-context,120.950,200.176,80.000,16.000,0.000,2.000,0.000,64.000
enc-attention-dense,425.184,139.612,16.000,22.002,0.500,8.000,0.000,36.000
enc-post-attention-dropout,106.335,98.276,22.002,14.000,0.000,12.000,8.000,72.000
enc-2nd-layernorm,78.475,151.676,14.000,22.000,0.000,8.031,11.969,72.000
enc-MLP-GEMM-1,127.137,426.126,22.000,22.002,2.000,8.000,12.000,36.000
enc-MLP-gelu,64.683,124.484,22.002,22.000,0.000,8.000,12.000,68.000
enc-MLP-GEMM-2,426.692,133.920,22.000,22.002,2.000,8.000,12.000,36.000
enc-post-MLP-dropout,105.661,98.509,22.002,14.000,0.000,12.000,8.000,72.000
final-layernorm,112.432,647.223,14.000,14.000,0.000,16.031,3.969,36.000
gpt-post-process,2374.452,1613.653,14.000,6.000,24.547,196.426,101.574,0.000
