op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,592.238,699.151,0.016,8.000,28.547,12.035,7.965,66.000
enc-1st-layernorm,79.173,222.403,8.000,16.000,0.000,8.031,11.969,72.000
enc-attention-qkv,262.016,611.991,16.000,14.000,1.500,6.000,0.000,40.000
enc-attention-score,127.912,243.831,14.000,74.000,0.000,64.000,64.000,128.000
enc-attention-softmax,139.272,133.413,74.000,74.000,0.000,64.000,0.000,192.000
enc-attention-dropout,150.621,132.352,74.000,74.000,0.000,96.000,0.000,256.000
enc-attention-context,120.950,200.176,74.000,10.000,0.000,2.000,0.000,64.000
enc-attention-dense,448.775,140.214,10.000,16.002,0.500,8.000,0.000,36.000
enc-post-attention-dropout,106.335,98.276,16.002,8.000,0.000,12.000,8.000,72.000
enc-2nd-layernorm,78.475,151.676,8.000,16.000,0.000,8.031,11.969,72.000
enc-MLP-GEMM-1,126.201,433.046,16.000,16.002,2.000,8.000,12.000,36.000
enc-MLP-gelu,64.683,124.484,16.002,16.000,0.000,8.000,12.000,68.000
enc-MLP-GEMM-2,429.618,131.935,16.000,16.002,2.000,8.000,12.000,36.000
enc-post-MLP-dropout,105.661,98.509,16.002,8.000,0.000,12.000,8.000,72.000
final-layernorm,112.432,647.223,8.000,8.000,0.000,16.031,3.969,36.000
gpt-post-process,2374.452,1613.653,8.000,0.000,24.547,196.426,101.574,0.000
