op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,938.320,1916.951,0.031,40.000,333.125,50.035,109.965,462.000
enc-1st-layernorm,75.114,302.279,40.000,80.000,0.000,40.031,0.000,160.000
enc-attention-qkv,1819.211,587.195,50.000,160.000,18.750,120.000,120.000,120.000
enc-attention-score,252.593,536.615,100.000,336.000,0.000,256.000,256.000,30.000
enc-attention-softmax,1471.066,2397.132,336.000,336.000,0.000,256.000,256.000,512.000
enc-attention-dropout,507.891,444.287,336.000,336.000,0.000,320.000,0.000,512.000
enc-attention-context,288.868,498.605,336.000,80.000,0.000,10.000,0.000,266.000
enc-attention-dense,640.053,140.572,80.000,110.010,6.250,40.000,0.000,50.000
enc-post-attention-dropout,245.082,142.169,110.010,70.000,0.000,50.000,30.000,160.000
enc-2nd-layernorm,72.640,293.726,70.000,110.000,0.000,40.031,0.000,160.000
enc-MLP-GEMM-1,397.259,975.227,110.000,110.010,25.000,40.000,0.000,80.000
enc-MLP-gelu,71.430,154.489,110.010,110.000,0.000,40.000,0.000,160.000
enc-MLP-GEMM-2,932.866,393.122,110.000,110.010,25.000,40.000,0.000,80.000
enc-post-MLP-dropout,242.966,140.959,110.010,70.000,0.000,50.000,30.000,160.000
final-layernorm,140.429,656.939,70.000,70.000,0.000,80.031,0.000,80.000
gpt-post-process,8297.080,6154.293,70.000,30.000,313.125,502.051,0.000,0.000
