op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,532.997,746.763,0.016,8.000,106.188,10.018,9.982,140.000
enc-1st-layernorm,58.210,144.255,8.000,16.000,0.000,8.016,0.000,40.000
enc-attention-qkv,271.058,482.363,16.000,20.000,6.000,12.000,8.000,20.000
enc-attention-score,128.210,256.693,20.000,140.000,0.000,128.000,128.000,20.000
enc-attention-softmax,743.979,1210.862,140.000,140.000,0.000,128.000,128.000,256.000
enc-attention-dropout,253.767,228.620,140.000,140.000,0.000,160.000,0.000,256.000
enc-attention-context,141.793,253.057,140.000,12.000,0.000,4.000,0.000,128.000
enc-attention-dense,344.300,173.706,12.000,16.004,2.000,8.000,0.000,20.000
enc-post-attention-dropout,82.594,105.935,16.004,8.000,0.000,10.000,10.000,36.000
enc-2nd-layernorm,63.431,137.895,8.000,16.000,0.000,8.016,0.000,40.000
enc-MLP-GEMM-1,97.626,399.703,16.000,24.008,8.000,16.000,0.000,36.000
enc-MLP-gelu,55.838,130.785,24.008,24.000,0.000,16.000,0.000,64.000
enc-MLP-GEMM-2,387.567,146.568,24.000,16.004,8.000,8.000,0.000,36.000
enc-post-MLP-dropout,79.012,97.293,16.004,8.000,0.000,10.000,10.000,36.000
final-layernorm,67.925,417.691,8.000,8.000,0.000,8.016,0.000,20.000
gpt-post-process,2415.532,1569.498,8.000,0.000,98.188,196.400,1.600,0.000
