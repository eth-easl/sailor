op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,840.300,2860.689,0.031,40.000,646.250,50.035,0.000,628.000
enc-1st-layernorm,74.911,300.056,40.000,80.000,0.000,40.031,0.000,160.000
enc-attention-qkv,1859.933,871.217,60.000,160.000,37.500,120.000,120.000,140.000
enc-attention-score,489.193,1012.969,120.000,592.000,0.000,512.000,512.000,60.000
enc-attention-softmax,2932.614,4768.991,592.000,592.000,0.000,512.000,512.000,1024.000
enc-attention-dropout,1012.069,878.334,592.000,592.000,0.000,640.000,0.000,1024.000
enc-attention-context,558.716,963.032,592.000,80.000,0.000,20.000,20.000,532.000
enc-attention-dense,630.820,210.667,80.000,100.010,12.500,40.000,0.000,60.000
enc-post-attention-dropout,250.477,145.334,100.010,60.000,0.000,50.000,30.000,160.000
enc-2nd-layernorm,72.783,292.087,60.000,100.000,0.000,40.031,0.000,160.000
enc-MLP-GEMM-1,803.155,1280.963,100.000,140.020,50.000,80.000,0.000,120.000
enc-MLP-gelu,139.976,275.755,140.020,140.000,0.000,80.000,0.000,270.000
enc-MLP-GEMM-2,1184.201,796.258,140.000,100.010,50.000,40.000,0.000,120.000
enc-post-MLP-dropout,243.789,140.685,100.010,60.000,0.000,50.000,30.000,160.000
final-layernorm,140.631,656.170,60.000,60.000,0.000,80.031,0.000,80.000
gpt-post-process,16034.323,11647.844,60.000,20.000,626.250,1002.051,0.000,0.000
