op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,534.320,848.752,0.031,16.000,106.188,20.035,43.965,170.000
enc-1st-layernorm,57.226,134.838,16.000,32.000,0.000,16.031,0.000,64.000
enc-attention-qkv,795.460,237.161,24.000,64.000,6.000,48.000,48.000,68.000
enc-attention-score,240.481,467.944,48.000,288.000,0.000,256.000,256.000,40.000
enc-attention-softmax,1473.153,2397.949,288.000,288.000,0.000,256.000,256.000,512.000
enc-attention-dropout,511.992,445.068,288.000,288.000,0.000,320.000,0.000,512.000
enc-attention-context,258.875,470.173,288.000,32.000,0.000,8.000,12.000,256.000
enc-attention-dense,381.929,129.557,32.000,40.004,2.000,16.000,0.000,16.000
enc-post-attention-dropout,97.841,96.488,40.004,24.000,0.000,20.000,12.000,64.000
enc-2nd-layernorm,57.316,132.942,24.000,40.000,0.000,16.031,0.000,64.000
enc-MLP-GEMM-1,146.556,486.726,40.000,56.008,8.000,32.000,0.000,48.000
enc-MLP-gelu,58.216,132.203,56.008,56.000,0.000,32.000,0.000,128.000
enc-MLP-GEMM-2,424.314,150.889,56.000,40.004,8.000,16.000,0.000,48.000
enc-post-MLP-dropout,95.373,98.413,40.004,24.000,0.000,20.000,12.000,64.000
final-layernorm,85.384,652.009,24.000,24.000,0.000,32.031,0.000,32.000
gpt-post-process,4443.979,2727.562,24.000,8.000,98.188,392.801,1.199,0.000
