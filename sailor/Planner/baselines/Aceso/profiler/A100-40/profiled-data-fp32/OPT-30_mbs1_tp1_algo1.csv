op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,600.547,5253.512,0.016,56.000,1430.625,70.000,168.000,1376.000
enc-1st-layernorm,141.567,487.924,56.000,112.000,0.000,56.016,0.000,224.000
enc-attention-qkv,5511.260,4904.705,112.000,224.000,588.000,168.000,0.000,0.000
enc-attention-score,962.543,1890.504,224.000,1008.000,0.000,896.000,896.000,168.000
enc-attention-softmax,5113.494,8308.238,1008.000,1008.000,0.000,896.000,896.000,1792.000
enc-attention-dropout,1761.633,1534.122,1008.000,1008.000,0.000,1120.000,0.000,1792.000
enc-attention-context,1012.540,1812.190,1008.000,112.000,0.000,56.000,56.000,952.000
enc-attention-dense,1765.108,1692.587,112.000,112.027,196.000,56.000,0.000,0.000
enc-post-attention-dropout,335.753,191.206,112.027,56.000,0.000,70.000,42.000,222.000
enc-2nd-layernorm,140.440,471.300,56.000,112.000,0.000,56.016,0.000,224.000
enc-MLP-GEMM-1,6803.435,6202.722,112.000,280.109,784.000,224.000,0.000,0.000
enc-MLP-gelu,371.188,709.844,280.109,280.000,0.000,224.000,0.000,560.000
enc-MLP-GEMM-2,7311.988,6087.625,280.000,112.027,784.000,56.000,0.000,0.000
enc-post-MLP-dropout,341.100,190.741,112.027,56.000,0.000,70.000,42.000,222.000
final-layernorm,141.335,409.204,56.000,56.000,0.000,56.016,0.000,112.000
gpt-post-process,13211.566,11277.294,56.000,0.000,1374.625,392.775,1.225,0.000
