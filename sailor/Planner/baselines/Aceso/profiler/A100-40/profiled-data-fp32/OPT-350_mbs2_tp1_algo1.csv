op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,246.590,1051.414,0.031,16.000,204.375,20.000,28.000,216.000
enc-1st-layernorm,57.405,134.325,16.000,32.000,0.000,16.031,0.000,64.000
enc-attention-qkv,393.897,294.095,32.000,64.000,12.000,48.000,48.000,64.000
enc-attention-score,462.139,917.035,64.000,544.000,0.000,512.000,512.000,48.000
enc-attention-softmax,2932.471,4770.434,544.000,544.000,0.000,512.000,512.000,1024.000
enc-attention-dropout,1013.803,879.806,544.000,544.000,0.000,640.000,0.000,1024.000
enc-attention-context,508.380,911.826,544.000,32.000,0.000,16.000,16.000,528.000
enc-attention-dense,90.551,114.059,32.000,32.004,4.000,16.000,0.000,32.000
enc-post-attention-dropout,97.811,97.370,32.004,16.000,0.000,20.000,12.000,64.000
enc-2nd-layernorm,58.043,133.300,16.000,32.000,0.000,16.031,0.000,64.000
enc-MLP-GEMM-1,288.445,333.089,32.000,80.016,16.000,64.000,0.000,80.000
enc-MLP-gelu,113.273,230.765,80.016,80.000,0.000,64.000,0.000,236.000
enc-MLP-GEMM-2,321.668,286.710,80.000,32.004,16.000,16.000,0.000,80.000
enc-post-MLP-dropout,97.549,97.007,32.004,16.000,0.000,20.000,12.000,64.000
final-layernorm,85.837,649.488,16.000,16.000,0.000,32.031,0.000,32.000
gpt-post-process,8324.814,4400.331,16.000,0.000,196.375,786.051,0.000,0.000
