op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,492.311,1020.509,0.016,8.000,106.188,10.018,9.982,120.000
enc-1st-layernorm,54.133,125.808,8.000,16.000,0.000,8.016,0.000,40.000
enc-attention-qkv,551.432,976.533,16.000,20.000,6.000,12.000,8.000,20.000
enc-attention-score,370.544,766.736,20.000,140.000,0.000,128.000,128.000,20.000
enc-attention-softmax,1114.917,2056.360,140.000,140.000,0.000,128.000,128.000,256.000
enc-attention-dropout,398.564,368.774,140.000,140.000,0.000,160.000,0.000,256.000
enc-attention-context,393.337,712.234,140.000,12.000,0.000,4.000,0.000,128.000
enc-attention-dense,475.383,185.978,12.000,16.004,2.000,8.000,0.000,20.000
enc-post-attention-dropout,85.908,99.123,16.004,8.000,0.000,10.000,10.000,36.000
enc-2nd-layernorm,56.326,125.104,8.000,16.000,0.000,8.016,0.000,40.000
enc-MLP-GEMM-1,616.759,1033.986,16.000,24.008,8.000,16.000,0.000,36.000
enc-MLP-gelu,47.994,119.478,24.008,24.000,0.000,16.000,0.000,64.000
enc-MLP-GEMM-2,972.539,701.362,24.000,16.004,8.000,8.000,0.000,36.000
enc-post-MLP-dropout,86.302,97.096,16.004,8.000,0.000,10.000,10.000,36.000
final-layernorm,55.593,429.910,8.000,8.000,0.000,8.016,0.000,20.000
gpt-post-process,9339.827,7986.742,8.000,0.000,98.188,196.400,1.600,0.000
