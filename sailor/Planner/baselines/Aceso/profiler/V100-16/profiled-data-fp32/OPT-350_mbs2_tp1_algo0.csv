op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,272.018,1498.562,0.031,16.000,204.375,20.000,28.000,216.000
enc-1st-layernorm,51.832,186.014,16.000,32.000,0.000,16.031,0.000,64.000
enc-attention-qkv,1940.215,1948.619,32.000,64.000,12.000,48.000,48.000,64.000
enc-attention-score,1546.425,2929.491,64.000,544.000,0.000,512.000,512.000,48.000
enc-attention-softmax,4397.959,8192.360,544.000,544.000,0.000,512.000,512.000,1024.000
enc-attention-dropout,1664.007,1451.641,544.000,544.000,0.000,640.000,0.000,1024.000
enc-attention-context,1495.552,2834.475,544.000,32.000,0.000,16.000,16.000,528.000
enc-attention-dense,733.250,606.430,32.000,32.004,4.000,16.000,0.000,32.000
enc-post-attention-dropout,175.363,104.427,32.004,16.000,0.000,20.000,12.000,64.000
enc-2nd-layernorm,56.285,194.567,16.000,32.000,0.000,16.031,0.000,64.000
enc-MLP-GEMM-1,2485.460,2354.324,32.000,80.016,16.000,64.000,0.000,80.000
enc-MLP-gelu,175.595,344.473,80.016,80.000,0.000,64.000,0.000,208.000
enc-MLP-GEMM-2,2409.369,2433.640,80.000,32.004,16.000,16.000,0.000,64.000
enc-post-MLP-dropout,160.038,97.811,32.004,16.000,0.000,20.000,12.000,64.000
final-layernorm,95.397,557.148,16.000,16.000,0.000,32.031,0.000,32.000
gpt-post-process,35851.777,29476.607,16.000,0.000,196.375,786.051,0.000,0.000
