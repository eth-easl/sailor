op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,491.756,4017.872,0.016,20.000,636.250,30.000,0.000,628.000
enc-1st-layernorm,84.877,265.539,20.000,40.000,0.000,20.031,0.000,160.000
enc-attention-qkv,1978.719,1778.793,40.000,80.000,37.500,60.000,60.000,200.000
enc-attention-score,1302.326,1920.134,80.000,552.000,0.000,512.000,512.000,1084.000
enc-attention-softmax,1185.352,1479.071,552.000,552.000,0.000,512.000,0.000,1536.000
enc-attention-dropout,1900.941,1616.055,552.000,552.000,0.000,768.000,0.000,2048.000
enc-attention-context,1145.941,2139.658,552.000,40.000,0.000,20.000,20.000,572.000
enc-attention-dense,583.714,557.852,40.000,40.005,12.500,20.000,0.000,80.000
enc-post-attention-dropout,233.859,133.628,40.005,20.000,0.000,30.000,10.000,160.000
enc-2nd-layernorm,86.349,280.976,20.000,40.000,0.000,20.031,0.000,160.000
enc-MLP-GEMM-1,2357.405,2173.162,40.000,100.020,50.000,80.000,0.000,260.000
enc-MLP-gelu,226.349,421.023,100.020,100.000,0.000,80.000,0.000,400.000
enc-MLP-GEMM-2,2328.855,2304.077,100.000,40.005,50.000,20.000,0.000,140.000
enc-post-MLP-dropout,231.004,128.675,40.005,20.000,0.000,30.000,10.000,160.000
final-layernorm,146.037,571.352,20.000,20.000,0.000,40.031,0.000,80.000
gpt-post-process,50651.151,35717.648,20.000,0.000,626.250,2004.051,1001.949,0.000
