op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,6838.143,2267.724,0.016,20.000,333.125,25.018,74.982,374.000
enc-1st-layernorm,68.939,252.336,20.000,40.000,0.000,20.016,0.000,80.000
enc-attention-qkv,20096.087,685.370,25.000,80.000,18.750,60.000,60.000,60.000
enc-attention-score,291.771,541.723,50.000,168.000,0.000,128.000,128.000,20.000
enc-attention-softmax,1215.869,2030.677,168.000,168.000,0.000,128.000,128.000,256.000
enc-attention-dropout,377.595,363.338,168.000,168.000,0.000,160.000,0.000,256.000
enc-attention-context,278.819,568.265,168.000,40.000,0.000,5.000,0.000,128.000
enc-attention-dense,6738.627,185.400,40.000,55.010,6.250,20.000,0.000,20.000
enc-post-attention-dropout,191.212,144.064,55.010,35.000,0.000,25.000,15.000,80.000
enc-2nd-layernorm,112.343,252.151,35.000,55.000,0.000,20.016,0.000,80.000
enc-MLP-GEMM-1,713.968,7308.584,55.000,55.010,25.000,20.000,0.000,40.000
enc-MLP-gelu,54.711,115.496,55.010,55.000,0.000,20.000,0.000,80.000
enc-MLP-GEMM-2,7266.307,709.981,55.000,55.010,25.000,20.000,0.000,40.000
enc-post-MLP-dropout,191.039,115.925,55.010,35.000,0.000,25.000,15.000,80.000
final-layernorm,70.852,564.498,35.000,35.000,0.000,20.016,0.000,40.000
gpt-post-process,11517.984,15393.108,35.000,15.000,313.125,250.525,1.475,0.000
