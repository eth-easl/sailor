op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,10829.771,1268.107,0.062,32.000,57.094,40.070,87.930,194.000
enc-1st-layernorm,93.883,353.038,32.000,64.000,0.000,32.062,0.000,128.000
enc-attention-qkv,32637.256,686.115,40.000,128.000,3.000,96.000,96.000,96.000
enc-attention-score,518.709,809.228,80.000,320.000,0.000,256.000,256.000,40.000
enc-attention-softmax,2440.196,4039.407,320.000,320.000,0.000,256.000,256.000,512.000
enc-attention-dropout,750.017,719.774,320.000,320.000,0.000,320.000,0.000,512.000
enc-attention-context,417.680,949.860,320.000,64.000,0.000,8.000,12.000,256.000
enc-attention-dense,10455.310,155.467,64.000,88.004,1.000,32.000,0.000,32.000
enc-post-attention-dropout,299.692,175.244,88.004,56.000,0.000,40.000,24.000,126.000
enc-2nd-layernorm,92.083,366.002,56.000,88.000,0.000,32.062,0.000,128.000
enc-MLP-GEMM-1,510.752,10443.455,88.000,88.004,4.000,32.000,0.000,64.000
enc-MLP-gelu,84.913,178.468,88.004,88.000,0.000,32.000,0.000,126.000
enc-MLP-GEMM-2,10794.955,508.410,88.000,88.004,4.000,32.000,0.000,64.000
enc-post-MLP-dropout,299.907,175.339,88.004,56.000,0.000,40.000,24.000,126.000
final-layernorm,173.312,729.811,56.000,56.000,0.000,64.062,0.000,64.000
gpt-post-process,9897.614,16256.028,56.000,24.000,49.094,392.852,1.148,0.000
