op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,46599.394,1144.195,0.062,32.000,32.547,40.070,87.930,108.000
enc-1st-layernorm,91.326,352.991,32.000,64.000,0.000,32.062,0.000,128.000
enc-attention-qkv,135486.883,464.791,36.000,128.000,1.500,96.000,96.000,96.000
enc-attention-score,249.022,388.408,72.000,192.000,0.000,128.000,128.000,20.000
enc-attention-softmax,1218.802,2035.969,192.000,192.000,0.000,128.000,128.000,256.000
enc-attention-dropout,377.059,362.402,192.000,192.000,0.000,160.000,0.000,256.000
enc-attention-context,198.990,425.810,192.000,64.000,0.000,4.000,0.000,128.000
enc-attention-dense,44219.649,161.517,64.000,92.004,0.500,32.000,0.000,32.000
enc-post-attention-dropout,299.603,177.020,92.004,60.000,0.000,40.000,24.000,126.000
enc-2nd-layernorm,95.350,364.649,60.000,92.000,0.000,32.062,0.000,128.000
enc-MLP-GEMM-1,291.640,43689.185,92.000,76.002,2.000,16.000,0.000,48.000
enc-MLP-gelu,56.571,184.065,76.002,76.000,0.000,16.000,0.000,64.000
enc-MLP-GEMM-2,44084.477,291.455,76.000,92.004,2.000,32.000,0.000,48.000
enc-post-MLP-dropout,299.901,177.401,92.004,60.000,0.000,40.000,24.000,126.000
final-layernorm,173.336,902.724,60.000,60.000,0.000,64.062,0.000,64.000
gpt-post-process,7053.429,46605.861,60.000,28.000,24.547,196.477,1.523,0.000
