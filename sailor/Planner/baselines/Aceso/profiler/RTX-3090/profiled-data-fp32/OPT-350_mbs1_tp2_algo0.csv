op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,389.773,945.932,0.016,8.000,106.188,10.018,9.982,120.000
enc-1st-layernorm,50.819,216.275,8.000,16.000,0.000,8.016,0.000,40.000
enc-attention-qkv,259.101,763.535,16.000,20.000,6.000,12.000,8.000,20.000
enc-attention-score,247.443,387.025,20.000,140.000,0.000,128.000,128.000,20.000
enc-attention-softmax,1211.292,2020.878,140.000,140.000,0.000,128.000,128.000,256.000
enc-attention-dropout,376.922,363.630,140.000,140.000,0.000,160.000,0.000,256.000
enc-attention-context,203.252,437.737,140.000,12.000,0.000,4.000,0.000,128.000
enc-attention-dense,395.852,138.152,12.000,16.004,2.000,8.000,0.000,20.000
enc-post-attention-dropout,82.070,145.757,16.004,8.000,0.000,10.000,10.000,36.000
enc-2nd-layernorm,107.509,213.069,8.000,16.000,0.000,8.016,0.000,40.000
enc-MLP-GEMM-1,295.389,714.046,16.000,24.008,8.000,16.000,0.000,36.000
enc-MLP-gelu,152.504,115.269,24.008,24.000,0.000,16.000,0.000,64.000
enc-MLP-GEMM-2,600.374,293.756,24.000,16.004,8.000,8.000,0.000,36.000
enc-post-MLP-dropout,81.712,145.209,16.004,8.000,0.000,10.000,10.000,36.000
final-layernorm,71.740,516.176,8.000,8.000,0.000,8.016,0.000,20.000
gpt-post-process,5113.053,4415.888,8.000,0.000,98.188,196.400,1.600,0.000
