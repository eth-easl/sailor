op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,5157.244,459.033,0.008,4.000,16.273,6.018,0.000,34.000
enc-1st-layernorm,70.912,155.574,4.000,8.000,0.000,4.016,0.000,20.000
enc-attention-qkv,17327.648,233.722,4.500,16.000,0.750,12.000,12.000,20.000
enc-attention-score,92.632,205.612,9.000,24.000,0.000,16.000,16.000,34.000
enc-attention-softmax,436.604,639.057,24.000,24.000,0.000,48.000,32.000,112.000
enc-attention-dropout,95.701,81.360,24.000,24.000,0.000,24.000,0.000,64.000
enc-attention-context,103.706,172.698,24.000,8.000,0.000,0.500,0.000,18.000
enc-attention-dense,5358.869,143.886,8.000,11.502,0.250,4.000,0.000,0.000
enc-post-attention-dropout,91.302,114.006,11.502,7.500,0.000,6.375,0.000,36.000
enc-2nd-layernorm,69.857,202.316,7.500,11.500,0.000,4.016,0.000,40.000
enc-MLP-GEMM-1,92.918,5471.891,11.500,9.501,1.000,2.000,0.000,0.000
enc-MLP-gelu,55.522,143.868,9.501,9.500,0.000,2.000,0.000,0.000
enc-MLP-GEMM-2,5450.159,143.182,9.500,11.502,1.000,4.000,0.000,20.000
enc-post-MLP-dropout,87.589,111.777,11.502,7.500,0.000,6.375,0.000,36.000
final-layernorm,94.652,417.924,7.500,7.500,0.000,4.016,0.000,20.000
gpt-post-process,1698.440,6235.242,7.500,3.500,12.273,50.025,25.975,0.000
