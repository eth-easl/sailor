op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1577.443,1531.529,0.062,32.000,53.094,48.141,95.859,250.000
enc-1st-layernorm,101.650,350.064,32.000,64.000,0.000,32.125,0.000,256.000
enc-attention-qkv,908.023,1952.791,64.000,80.000,3.000,48.000,48.000,176.000
enc-attention-score,802.171,1455.128,80.000,560.000,0.000,512.000,512.000,1072.000
enc-attention-softmax,990.546,1268.905,560.000,560.000,0.000,512.000,0.000,1536.000
enc-attention-dropout,1885.468,1590.592,560.000,560.000,0.000,768.000,0.000,2048.000
enc-attention-context,768.620,1511.568,560.000,48.000,0.000,16.000,16.000,560.000
enc-attention-dense,1191.872,252.771,48.000,64.002,1.000,32.000,0.000,112.000
enc-post-attention-dropout,339.973,186.121,64.002,32.000,0.000,48.000,32.000,190.000
enc-2nd-layernorm,85.974,354.660,32.000,64.000,0.000,32.125,0.000,256.000
enc-MLP-GEMM-1,978.899,2007.866,64.000,96.004,4.000,64.000,0.000,224.000
enc-MLP-gelu,170.243,337.929,96.004,96.000,0.000,64.000,0.000,318.000
enc-MLP-GEMM-2,1863.611,953.442,96.000,64.002,4.000,32.000,0.000,160.000
enc-post-MLP-dropout,327.164,186.121,64.002,32.000,0.000,48.000,32.000,190.000
final-layernorm,175.333,651.610,32.000,32.000,0.000,64.125,0.000,128.000
gpt-post-process,30113.882,19123.065,32.000,0.000,49.094,1572.203,785.797,0.000
