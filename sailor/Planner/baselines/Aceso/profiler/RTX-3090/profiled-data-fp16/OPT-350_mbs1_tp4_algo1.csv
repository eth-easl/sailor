op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1210.195,496.578,0.008,4.000,28.547,6.018,0.000,46.000
enc-1st-layernorm,84.811,211.889,4.000,8.000,0.000,4.016,0.000,20.000
enc-attention-qkv,4228.622,271.624,5.000,16.000,1.500,12.000,12.000,22.000
enc-attention-score,120.282,196.004,10.000,40.000,0.000,32.000,32.000,66.000
enc-attention-softmax,131.702,155.115,40.000,40.000,0.000,32.000,0.000,96.000
enc-attention-dropout,120.169,126.058,40.000,40.000,0.000,48.000,0.000,128.000
enc-attention-context,103.658,259.364,40.000,8.000,0.000,1.000,1.000,34.000
enc-attention-dense,1340.872,146.878,8.000,11.002,0.500,4.000,0.000,2.000
enc-post-attention-dropout,93.955,138.485,11.002,7.000,0.000,6.000,0.000,36.000
enc-2nd-layernorm,101.769,213.152,7.000,11.000,0.000,4.016,0.000,40.000
enc-MLP-GEMM-1,117.260,1459.819,11.000,11.002,2.000,4.000,0.000,20.000
enc-MLP-gelu,58.949,205.088,11.002,11.000,0.000,4.000,0.000,36.000
enc-MLP-GEMM-2,1333.690,89.526,11.000,11.002,2.000,4.000,0.000,20.000
enc-post-MLP-dropout,123.507,140.554,11.002,7.000,0.000,6.000,0.000,36.000
final-layernorm,89.538,507.367,7.000,7.000,0.000,4.016,0.000,20.000
gpt-post-process,2303.463,2692.956,7.000,3.000,24.547,98.213,51.787,0.000
