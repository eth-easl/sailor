op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,327.826,1951.319,0.031,16.000,204.375,20.000,28.000,216.000
enc-1st-layernorm,66.668,262.278,16.000,32.000,0.000,16.031,0.000,64.000
enc-attention-qkv,2128.494,2154.374,32.000,64.000,12.000,48.000,48.000,64.000
enc-attention-score,1913.905,3253.162,64.000,544.000,0.000,512.000,512.000,48.000
enc-attention-softmax,6696.427,11949.486,544.000,544.000,0.000,512.000,512.000,1024.000
enc-attention-dropout,2317.166,2165.788,544.000,544.000,0.000,640.000,0.000,1024.000
enc-attention-context,1970.899,3169.441,544.000,32.000,0.000,16.000,16.000,528.000
enc-attention-dense,662.750,687.987,32.000,32.004,4.000,16.000,0.000,32.000
enc-post-attention-dropout,245.512,145.197,32.004,16.000,0.000,20.000,12.000,64.000
enc-2nd-layernorm,67.151,262.302,16.000,32.000,0.000,16.031,0.000,64.000
enc-MLP-GEMM-1,2682.859,2568.120,32.000,80.016,16.000,64.000,0.000,80.000
enc-MLP-gelu,259.191,486.308,80.016,80.000,0.000,64.000,0.000,164.000
enc-MLP-GEMM-2,2735.829,2469.081,80.000,32.004,16.000,16.000,0.000,80.000
enc-post-MLP-dropout,227.803,147.110,32.004,16.000,0.000,20.000,12.000,64.000
final-layernorm,128.394,803.721,16.000,16.000,0.000,32.031,0.000,32.000
gpt-post-process,39302.498,33088.785,16.000,0.000,196.375,786.051,0.000,0.000
