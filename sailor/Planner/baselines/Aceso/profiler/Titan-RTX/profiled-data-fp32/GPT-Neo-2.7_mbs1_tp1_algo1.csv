op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,368.983,10005.087,0.016,20.000,1272.500,25.000,75.000,1254.000
enc-1st-layernorm,120.020,380.027,20.000,40.000,0.000,20.016,0.000,80.000
enc-attention-qkv,6726.909,5866.379,40.000,80.000,75.000,60.000,0.000,0.000
enc-attention-score,2316.415,5256.820,80.000,552.000,0.000,512.000,512.000,60.000
enc-attention-softmax,6688.899,11931.443,552.000,552.000,0.000,512.000,512.000,1024.000
enc-attention-dropout,2323.502,2165.031,552.000,552.000,0.000,640.000,0.000,1024.000
enc-attention-context,2931.297,4619.706,552.000,40.000,0.000,20.000,20.000,532.000
enc-attention-dense,2130.288,1950.634,40.000,40.010,25.000,20.000,0.000,0.000
enc-post-attention-dropout,281.924,165.737,40.010,20.000,0.000,25.000,35.000,78.000
enc-2nd-layernorm,108.343,375.962,20.000,40.000,0.000,20.016,0.000,80.000
enc-MLP-GEMM-1,8168.906,7387.489,40.000,100.039,100.000,80.000,0.000,0.000
enc-MLP-gelu,323.313,607.461,100.039,100.000,0.000,80.000,0.000,200.000
enc-MLP-GEMM-2,8995.956,7496.148,100.000,40.010,100.000,20.000,0.000,0.000
enc-post-MLP-dropout,280.529,164.402,40.010,20.000,0.000,25.000,35.000,78.000
final-layernorm,107.801,507.748,20.000,20.000,0.000,20.016,0.000,40.000
gpt-post-process,105667.382,91134.834,20.000,0.000,1252.500,1002.025,0.000,0.000
