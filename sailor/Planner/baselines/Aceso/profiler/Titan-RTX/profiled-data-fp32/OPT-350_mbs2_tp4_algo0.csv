op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,5924.261,1180.446,0.031,16.000,57.094,20.035,47.965,120.000
enc-1st-layernorm,66.543,262.117,16.000,32.000,0.000,16.031,0.000,64.000
enc-attention-qkv,551.462,5970.144,32.000,28.000,3.000,12.000,0.000,28.000
enc-attention-score,417.757,835.609,28.000,148.000,0.000,128.000,128.000,20.000
enc-attention-softmax,1692.110,2992.451,148.000,148.000,0.000,128.000,128.000,256.000
enc-attention-dropout,590.575,545.502,148.000,148.000,0.000,160.000,0.000,256.000
enc-attention-context,463.390,799.048,148.000,20.000,0.000,4.000,0.000,128.000
enc-attention-dense,5320.597,186.598,20.000,32.004,1.000,16.000,0.000,16.000
enc-post-attention-dropout,228.369,133.651,32.004,16.000,0.000,20.000,12.000,64.000
enc-2nd-layernorm,66.233,261.861,16.000,32.000,0.000,16.031,0.000,64.000
enc-MLP-GEMM-1,617.057,6039.053,32.000,32.004,4.000,16.000,0.000,32.000
enc-MLP-gelu,65.458,139.093,32.004,32.000,0.000,16.000,0.000,64.000
enc-MLP-GEMM-2,5759.680,588.858,32.000,32.004,4.000,16.000,0.000,32.000
enc-post-MLP-dropout,226.510,133.961,32.004,16.000,0.000,20.000,12.000,64.000
final-layernorm,128.621,773.275,16.000,16.000,0.000,32.031,0.000,32.000
gpt-post-process,10290.694,13379.937,16.000,0.000,49.094,196.426,1.574,0.000
