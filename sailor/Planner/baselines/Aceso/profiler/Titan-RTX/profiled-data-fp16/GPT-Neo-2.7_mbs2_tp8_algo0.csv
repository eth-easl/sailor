op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,8241.928,1637.053,0.016,20.000,88.281,30.035,59.965,238.000
enc-1st-layernorm,101.620,369.936,20.000,40.000,0.000,20.031,0.000,160.000
enc-attention-qkv,273.401,7673.407,40.000,27.500,4.688,7.812,0.000,60.000
enc-attention-score,179.017,287.861,27.500,86.500,0.000,64.000,64.000,128.000
enc-attention-softmax,203.931,256.747,86.500,86.500,0.000,64.000,0.000,192.000
enc-attention-dropout,331.718,304.145,86.500,86.500,0.000,96.000,0.000,256.000
enc-attention-context,151.908,310.206,86.500,22.500,0.000,2.500,0.000,64.000
enc-attention-dense,7216.376,215.888,22.500,40.005,1.562,20.000,0.000,60.000
enc-post-attention-dropout,303.149,175.548,40.005,20.000,0.000,30.000,20.000,118.000
enc-2nd-layernorm,107.533,365.674,20.000,40.000,0.000,20.031,0.000,160.000
enc-MLP-GEMM-1,301.939,7620.138,40.000,30.002,6.250,10.000,0.000,50.000
enc-MLP-gelu,50.664,118.101,30.002,30.000,0.000,10.000,0.000,78.000
enc-MLP-GEMM-2,7485.360,292.516,30.000,40.005,6.250,20.000,0.000,70.000
enc-post-MLP-dropout,300.938,174.618,40.005,20.000,0.000,30.000,20.000,118.000
final-layernorm,201.762,736.195,20.000,20.000,0.000,40.031,0.000,80.000
gpt-post-process,8259.338,11838.448,20.000,0.000,78.281,250.551,127.449,0.000
