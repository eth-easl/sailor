op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,3781.486,2052.522,0.008,10.000,166.562,15.018,34.982,198.000
enc-1st-layernorm,61.798,193.399,10.000,20.000,0.000,10.016,0.000,80.000
enc-attention-qkv,272.280,3840.810,20.000,17.500,9.375,7.500,12.500,30.000
enc-attention-score,179.350,286.496,17.500,76.500,0.000,64.000,64.000,148.000
enc-attention-softmax,201.476,257.558,76.500,76.500,0.000,64.000,0.000,192.000
enc-attention-dropout,332.427,305.635,76.500,76.500,0.000,96.000,0.000,256.000
enc-attention-context,151.134,310.493,76.500,12.500,0.000,2.500,0.000,84.000
enc-attention-dense,3446.788,173.926,12.500,20.005,3.125,10.000,0.000,30.000
enc-post-attention-dropout,155.157,105.041,20.005,10.000,0.000,15.000,15.000,78.000
enc-2nd-layernorm,80.806,191.242,10.000,20.000,0.000,10.016,0.000,80.000
enc-MLP-GEMM-1,297.987,3875.256,20.000,20.005,12.500,10.000,0.000,40.000
enc-MLP-gelu,46.545,129.789,20.005,20.000,0.000,10.000,0.000,78.000
enc-MLP-GEMM-2,3649.586,292.397,20.000,20.005,12.500,10.000,0.000,40.000
enc-post-MLP-dropout,156.140,138.336,20.005,10.000,0.000,15.000,15.000,78.000
final-layernorm,71.186,466.126,10.000,10.000,0.000,10.016,0.000,40.000
gpt-post-process,8123.261,8295.405,10.000,0.000,156.562,250.525,127.475,0.000
