op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1214.570,779.068,0.008,4.000,53.094,6.018,13.982,70.000
enc-1st-layernorm,58.949,168.580,4.000,8.000,0.000,4.016,0.000,20.000
enc-attention-qkv,3360.921,262.332,6.000,16.000,3.000,12.000,12.000,32.000
enc-attention-score,186.628,273.794,12.000,72.000,0.000,64.000,64.000,128.000
enc-attention-softmax,205.183,257.099,72.000,72.000,0.000,64.000,0.000,192.000
enc-attention-dropout,338.191,305.063,72.000,72.000,0.000,96.000,0.000,256.000
enc-attention-context,144.482,313.598,72.000,8.000,0.000,2.000,0.000,64.000
enc-attention-dense,1192.534,159.848,8.000,10.002,1.000,4.000,0.000,20.000
enc-post-attention-dropout,75.227,151.527,10.002,6.000,0.000,6.000,0.000,36.000
enc-2nd-layernorm,104.749,129.080,6.000,10.000,0.000,4.016,0.000,40.000
enc-MLP-GEMM-1,104.541,1395.303,10.000,14.004,4.000,8.000,0.000,36.000
enc-MLP-gelu,44.554,130.427,14.004,14.000,0.000,8.000,12.000,68.000
enc-MLP-GEMM-2,1291.579,132.173,14.000,10.002,4.000,4.000,0.000,20.000
enc-post-MLP-dropout,76.729,113.100,10.002,6.000,0.000,6.000,0.000,36.000
final-layernorm,66.489,512.904,6.000,6.000,0.000,4.016,0.000,20.000
gpt-post-process,4963.690,3694.242,6.000,2.000,49.094,196.400,101.600,0.000
