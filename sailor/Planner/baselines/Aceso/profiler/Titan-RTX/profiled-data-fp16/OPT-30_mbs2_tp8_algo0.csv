op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,23173.106,3185.081,0.016,56.000,113.914,84.035,167.965,530.000
enc-1st-layernorm,361.800,1107.788,56.000,112.000,0.000,56.031,0.000,448.000
enc-attention-qkv,1877.540,21467.388,112.000,77.000,36.750,21.000,1.000,126.000
enc-attention-score,296.247,559.372,77.000,175.000,0.000,112.000,112.000,224.000
enc-attention-softmax,4243.386,6529.242,175.000,175.000,0.000,336.000,224.000,784.000
enc-attention-dropout,573.540,526.214,175.000,175.000,0.000,168.000,0.000,448.000
enc-attention-context,288.582,543.028,175.000,63.000,0.000,7.000,0.000,112.000
enc-attention-dense,20206.445,577.772,63.000,112.014,12.250,56.000,0.000,168.000
enc-post-attention-dropout,826.257,478.375,112.014,56.000,0.000,84.000,28.000,264.000
enc-2nd-layernorm,361.568,1096.129,56.000,112.000,0.000,56.031,0.000,448.000
enc-MLP-GEMM-1,2490.604,21659.458,112.000,84.007,49.000,28.000,0.000,140.000
enc-MLP-gelu,112.957,227.624,84.007,84.000,0.000,28.000,0.000,150.000
enc-MLP-GEMM-2,21698.129,2099.991,84.000,112.014,49.000,56.000,0.000,196.000
enc-post-MLP-dropout,826.359,477.511,112.014,56.000,0.000,84.000,28.000,264.000
final-layernorm,593.752,924.039,56.000,56.000,0.000,112.031,0.000,224.000
gpt-post-process,9030.676,25211.370,56.000,0.000,85.914,98.238,51.762,0.000
