op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,12527.102,4145.306,0.031,40.000,323.125,60.070,119.930,630.000
enc-1st-layernorm,188.446,722.313,40.000,80.000,0.000,40.062,0.000,320.000
enc-attention-qkv,2254.200,12623.274,80.000,100.000,18.750,60.000,40.000,220.000
enc-attention-score,1334.143,2264.911,100.000,572.000,0.000,512.000,512.000,1084.000
enc-attention-softmax,1579.344,1986.003,572.000,572.000,0.000,512.000,0.000,1536.000
enc-attention-dropout,2592.075,2373.809,572.000,572.000,0.000,768.000,0.000,2048.000
enc-attention-context,1233.625,2314.961,572.000,60.000,0.000,20.000,20.000,572.000
enc-attention-dense,11054.420,546.390,60.000,80.005,6.250,40.000,0.000,140.000
enc-post-attention-dropout,598.997,341.386,80.005,40.000,0.000,60.000,40.000,198.000
enc-2nd-layernorm,201.356,713.784,40.000,80.000,0.000,40.062,0.000,320.000
enc-MLP-GEMM-1,2549.672,12532.026,80.000,120.010,25.000,80.000,0.000,280.000
enc-MLP-gelu,317.401,610.787,120.010,120.000,0.000,80.000,0.000,358.000
enc-MLP-GEMM-2,12460.023,2117.008,120.000,80.005,25.000,40.000,0.000,200.000
enc-post-MLP-dropout,597.513,343.055,80.005,40.000,0.000,60.000,40.000,198.000
final-layernorm,395.918,675.744,40.000,40.000,0.000,80.062,0.000,160.000
gpt-post-process,64006.245,46695.381,40.000,0.000,313.125,2004.102,1001.898,0.000
